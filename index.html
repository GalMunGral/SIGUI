<head>
  <meta name="viewport" content="initial-scale=1, user-scalable=no" />
  <style>
    body {
      user-select: none;
      max-width: 600px;
      padding: 40px;
      margin: auto;
      overflow-x: hidden;
    }

    input[type="number"] {
      width: 50px;
      margin-right: 10px;
    }

    label {
      font-family: sans-serif;
      color: gray;
      font-size: 0.75em;
    }

    input[type="file"] {
      width: 200px;
    }

    pre {
      overflow: scroll;
    }

    canvas {
      width: 100%;
      height: 300px;
      box-shadow: 0 0 5px lightgray;
      margin: 20px 0;
      touch-action: none;
    }
  </style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>
</head>

<body>
  <h1>
    <em>
      Structure and Interpretation of User Interfaces: The Tao of Illusion</em
    >
  </h1>

  <div style="position: relative">
    <canvas id="raster"></canvas>
    <pre id="pointer-xy"></pre>
  </div>
  <script type="module" src="./demo/raster.js"></script>

  <p>
    In this day and age, user interfaces are as mundane a concept as light
    switches, door knobs and water faucets. We interact with the windows and
    button as if they are the same kind of natural, physical objects, despite
    understanding perfectly well that they are just a grid of pixels on a flat
    screen shifting colors over time. Such "user illusions" are an essential
    part of the human experience: We all <em>know</em> that we are made up of
    the same kinds of particles that make up stars and galaxies, and yet it's
    impossible to actually <em>see</em> ourselves this way, because of our
    deeply &mdash; perhaps biologically &mdash; ingrained belief of our spirit
    and soul.
  </p>
  <p>
    It's frustrating how inadequately people are educated about systems that are
    designed and engineered by ourselves. Ask a well educated person and they
    could probably give you a general picture of the natural world: from how
    different parts of the brain works to the orbits of electrons. The same
    cannot be said for computing systems as simple as user interfaces -- even
    people well educated in computer science don't necessarily bother to
    understand the nitty-gritty of it.
  </p>

  <p>
    In a traditional computer science curriculum, you learn about the basics of
    computer architecture and operating systems, about processes and threads,
    and perhaps the thing that underlies user interfaces: the event loop, which
    is simply this:
  </p>

  <blockquote>
    <pre>
  while !quit {
    if event = poll() {
      handle(event)
    }
    if dirty { 
      draw()
    }
  }
    </pre>
  </blockquote>
  <p>
    If you have ever wondered how user interfaces work, you will eventually
    discover plenty of artcles about event loops on the Internet, but this is
    only half of the magic. If we take the analogy between humans and user
    interfaces even further, the event loop is sort of like the nervous system.
    To qualify as a real person requires a fully developed brain, and the
    spirits that dwells therein, and this will be the focus of this article: to
    demonstrate some basic techniques to conjure up the spirits of user
    interfaces that reside behind the sheet of pixels, using two spells that
    complement each other:
  </p>
  <blockquote>
    <pre>
fn draw() {
  for (x,y) in shape {
    color(x, y)
  }
}

fn handle(event) {
  target = pick(event.x, event.y)
  target.handle(e)
}
    </pre>
  </blockquote>

  <h2><em>ยง1 - Polygons</em></h2>
  <p>We all know how to draw a rectangle with a simple nested loop:</p>
  <blockquote>
    <pre>
for y in y1...y2 {
  for x in x1...x2 {
    color(x, y)
  }
}

    </pre>
  </blockquote>
  <p>
    This idea can be extended to arbitrary closed shapes, except the scan line
    \(y = k\) could now <em>enter and leave the shape any number of times</em>.
    Suppose the scan line crosses the boundary at x-coordinates \(x_1, x_2,
    ...x_n\). We know \(n\) must be even, and all we need to do is to traverse
    the odd-even intervals (from \(x_1\) to \(x_2\), from \(x_3\) to \(x_4\),
    etc.):
  </p>
  <blockquote>
    <pre>
for y in y1...y2 {
  for (x1, x2) in intervals(y) {
    for x in x1...x2 {
      color(x, y)
    }
  }
}
    </pre>
  </blockquote>
  <p>
    The way we traverse the interior of the shape also tells us how we should
    check if a integer point \((x,y)\) lies within it. If it is, \(x\) must be
    in one of those intervals, and since we are in the middle of an interval,
    <em>there must be odd number of intersection points on either side</em>
    &mdash; this is all we need for a hit-test:
  </p>
  <blockquote>
    <em>
      Given a point \((x_p,y_p)\), count the number of intersections of scan
      line \(y = y_p\) and the curve with a \(x\) coordinate greater than
      \(x_p\). if the number is even, then the point is on the outside; if it is
      odd, then the point is on the inside.
    </em>
  </blockquote>
  <p>
    Now the question is: How do we find such intersection points? Thing would be
    a lot eaiser if we can replace the curve with am approximating polygon, in
    which case we can narrow our focus on the edges that straddle the scan line
    \(y\). Suppose an edge has two endpoints \((x_1,y_1)\) (inclusive) and
    \((x_2, y_2)\) (exclusive), where \(y_1 < y_2\). An intersection point
    exists if and only if \(y_1 \leq y < y_2\), and we can easily compute the
    intersection point: $$intersection=\left(x_1 +
    \frac{x_2-x_1}{y_2-y_1}(y-y_1), y\right)$$ The slope of line segment
    $$k=\frac{\Delta x}{\Delta y}=\frac{x_2-x_1}{y_2-y_1}$$ tells us the how
    much \(x\) changes when we increase \(y\) by \(1\). This is handy because
    once we find the first intersection point \((x, y)\) we could easily get the
    next one \((x+k, y+1)\), and we can do this incrementation until \(y \geq
    y_2\) and they no longer intersect.
  </p>

  <p>Here is the scan-line rasterization algorithm:</p>
  <blockquote>
    <em
      >We keep track of all currently intersecting edges, which gives us a list
      of \((x_1,x_2)\) ranges to traverse through for the current \(y\). At the
      end of each iteration we increment \(y\), discard those edges that no
      longer intersect with the scan line, increment the remaining ones by \((k,
      1)\), and add new edges that now intersect with the scan line for the
      first time.</em
    >
  </blockquote>
  <p>
    Try clicking on the canvas below. It should draw a polygon from the points
    you selected, and when you hover your mouse over the interior of the
    polygon, it should turn to dark red.
  </p>

  <canvas id="polygon"></canvas>
  <script type="module" src="./demo/polygon.js"></script>
  <p>
    We have now obtained the ability to draw any polygon on screen and test
    whether the pointer hits the polygon &mdash; I claim that this is the very
    essense of user interface!
  </p>
  <p>
    The first thing we can do is to applying linear transformations to our
    polygons. Since the polygon is defined by the vertices, the only thing we
    need to do is to
    <em>apply the same transformation to each vertex before rasterization</em>.
    If we use homogeneous coordinates \((x, y, 1)\) to represent the point on
    screen at \((x,y)\), translation, rotation and scaling effects can all be
    expressed neatly as \(3\times3\) matrices: $$T(x,y) = \begin{pmatrix} 1 & 0
    & x \\ 0 & 1 & y \\ 0 & 0 & 1 \end{pmatrix}, R(\theta) = \begin{pmatrix}
    \cos\theta & -\sin\theta & 0 \\ \sin\theta & \cos\theta & 0 \\ 0 & 0 & 1
    \end{pmatrix}, S(c) = \begin{pmatrix} c & 0 & 0 \\ 0 & c & 0 \\ 0 & 0 & 1
    \end{pmatrix}$$ Try dragging the square below to see these transforms in
    action:
  </p>

  <canvas id="transform"></canvas>
  <script type="module" src="./demo/transform.js"></script>

  <p>
    Look what we can already create with nothing but nested loops and simple
    algebra! What's more exciting is that polygons are in fact all we need to
    draw any shape, whether it's smooth or not, by taking dicrete samples \(p_1,
    p_2, ...p_N\) along the curve. The magic happens when the discretization
    becomes so fine that the distances between two adjacent vertices are less
    the size of a single pixel &mdash; if you have heard that video games are
    made up of millions of tiny triangles, it's exactly the same idea.
  </p>
  <p>
    Let's draw an elliptic arc to get a feel of this: Suppose we want an arc
    from angle \(\phi_1\) to \(\phi_2\) on a ellipse with semi-major axis \(a\)
    and semi-minor axis \(b\), centered at \((x,y)\), and rotated by an angle
    \(\theta\). We can create a polyon with \(N + 1\) points from the curve,
    using this formula: $$\begin{pmatrix}x_i\\y_i\end{pmatrix} = T(x, y) \cdot
    R(\theta) \cdot \left(a\cos\left(\phi_1 + i \cdot\frac{\phi_2 -
    \phi_1}{N}\right), b\sin\left(\phi_1 + i\cdot\frac{\phi_2 -
    \phi_1}{N}\right)\right)^\top$$
  </p>

  <div>
    <canvas id="ellipse"></canvas>
  </div>
  <div>
    <label>\(N =\)</label>
    <input id="ellipse-n" type="number" value="5" min="3" />
    <label>\(a= \)</label> <input id="ellipse-a" type="number" value="200" />
    <label>\(b =\)</label> <input id="ellipse-b" type="number" value="150" />
    <label>\(\theta= \)</label>
    <input id="ellipse-theta" type="number" value="45" />
    <label>\(\phi_1 =\)</label>
    <input id="ellipse-phi-1" type="number" value="0" />
    <label>\(\phi_2 =\)</label>
    <input id="ellipse-phi-2" type="number" value="360" />
  </div>
  <script type="module" src="./demo/ellipse.js"></script>

  <p>
    Try increasing \(N\) and see how the curve smooths out. I should remind you
    that we have used nothing but nested loops and some simple algebra! "But we
    can't possibly describe all shapes with formulas, can we?", you might say,
    "What about vector arts and fonts?"
  </p>

  <h2><em>ยง2 - Bรฉzier Curves</em></h2>
  <p>
    So far we have colored everything black, which isn't terribly intersting.
    One easy improvement we can make is to linearly interpolate between two
    colors. To linearly interpolate two values \(v_1\) and \(v_2\) just means to
    take take a weighted average $$interpolate(v_1, v_2, t) = (1-t) \cdot v_1 +
    t \cdot v_2$$ where the parameter \(t \in [0,1]\) controls how far we are
    from the starting point. It should be easy to see that as \(t\) goes from
    \(0\) to \(1\), the interpolated value changes continuously from \(v_1\) to
    \(v_2\). For color gradient, the parameter \(t\) is based on some sort of
    distance (e.g. Euclidean). For example, the two types of gradients below are
    computed as follows: $$LinearGradient(x,y) = interpolate\left(C_1, C_2,
    \frac{y - y_{min}}{y_{max} - y_{min}}\right)$$ $$RadialGradient(x,y) =
    interpolate\left(C_1, C_2, \frac{\sqrt{(x-x_o)^2 + (y-y_o)^2}}{r}\right)$$
  </p>

  <canvas id="gradient"></canvas>
  <div>
    <input id="gradient-color-1" type="color" value="#eeeeee" />
    <input id="gradient-color-2" type="color" value="#000000" />
  </div>
  <script type="module" src="./demo/gradient.js"></script>

  <p>
    Just as interpolating colors using position as the parameter gives us color
    gradients, interpolating positions using time as the paramter can gives us
    smooth curves! This is the famous Bรฉzier curve that we encounter in every
    corner (literally) of user interfaces, which can be defined by an iterative
    process: given control points \(p^{(0)}_0, p^{(0)}_1, \dots. p^{(0)}_n\), we
    can find the point \(B(t)\) by the following process:
  </p>
  <blockquote>
    <em
      >In each iteration \(k \in [1, n]\), we compute for each \(i \in [0, n -
      k]\), $$p^{(k)}_i = (1-t) \cdot p^{(k-1)}_i + t \cdot p^{(k-1)}_{i+1}$$
      Finally, \(B(t) := p^{(n)}_0\)</em
    >
  </blockquote>
  The idea of linearly interpolation should be straightforward: The point just
  travels from the starting point to the ending point at a constant speed. For
  higher-order Bรฉzier curves, we just do this recursively: Quadratic Bรฉzier is
  the interpolation of interpolation of control points; cubic Bรฉzier is the
  interpolation of interpolation of interpolation of control points, etc. The
  best way to understand this is to follow the iterative algorithm on paper and
  trace out the curve it generates. You could also click on the canvas below to
  generate a Bรฉzier curve from any number of control points.
  <canvas id="animation"></canvas>
  <script type="module" src="./demo/animation.js"></script>

  <p>
    You might have noticed some patterns: With quadratic Bรฉzier, we could create
    "C" curves, where \(p_1\) controls in which direction and how much the curve
    bends; With cubic Bรฉzier, we could not only create "C" curves with a greater
    arc, but also "S" curves, if we place \(p_1\) and \(p_2\) on different sides
    of the line connecting \(p_0\) and \(p_3\). Unfortunately, we don't have
    such intuitive explanation for the role of each control point for
    higher-order Bรฉzier curves, so quadratic and cubic are the types that you
    will see most of the time.
  </p>
  <p>
    To rasterize a region enclosed by Bรฉzier curves, we can apply the same trick
    that we used for elliptic arcs &mdash; we just sample \(N\) points on the
    curve at \(t = 0, 1/N, 2/N, \dots, 1\) and draw a polygon instead.
  </p>
  <p>
    Try creating some Bรฉzier shapes on the two canvases above. The first one
    generates quadratic curves and second one generates cubic curves. (You need
    to click twice in the first canvas and three times in the second one to
    create each new curve.) Did those shapes remind you of something?
  </p>
  <canvas id="quadratic-bezier"></canvas>
  <canvas id="cubic-bezier"></canvas>
  <p>
    Yes, every chracter you have read on this page &mdash; or on anything that
    uses OpenType or TrueType fonts for that matter &mdash; is in fact made of
    Bรฉzier curves!
  </p>
  <script type="module" src="./demo/bezier.js"></script>
  <canvas id="font"></canvas>
  <div>
    <label>font (OTF/TTF): </label>
    <input id="font-file" type="file" accept=".otf,.ttf" />
    <label>text </label>
    <input id="font-text" value="Hello, world!" />
    <label>size </label>
    <input id="font-size" type="number" step="1" value="50" />
  </div>
  <script type="module" src="./demo/font.js"></script>
  <p>
    When you hover your mouse over the painted text, its color should change to
    dark red &mdash; we are still drawing polygons! At this point maybe you
    should take a moment take it in: You now know how to create a text box,
    using nothing but nested loops &mdash;
    <em>event loop, rasterization, Bรฉzier interpolation</em> &mdash; and some
    algebra! Isn't it magical? If you have read this far, congratulations! You
    have almost ready to summon the spirit of user interfaces!
  </p>

  <h2><em>ยง3. Layers</em></h2>
  <p>
    Usually, objects on screen form a hierarchy: Shapes contain other shapes,
    and when a containing shape moves, everthing inside moves with it, thus it's
    convenient to represent the entire user interface as a tree structure. To
    render the tree to screen we simply do a preoder traversal (or multiple
    traversals). The reason that we use preorder is that the geometry of a
    container determines the geometries of its descendants, and a container
    needs to be drawn before its descendants because it lies underneath.
  </p>
  <blockquote>
    <pre>
fn layout(node) {
  computeGeometry(node)
  node.children.forEach(layout)
}

fn draw(node) {
  drawGeometry(node)
  node.children.forEach(draw)
}
    </pre>
  </blockquote>
  <p>
    For hit-testing, we need to determine the topmost polygon, i.e. the last
    drawn polygon, that covers the pointer position. In order to achieve this we
    must retain a record of the "draw calls" so that we can perform a search
    <em>in reverse draw order</em>. The algorithm is straighforward:
  </p>
  <blockquote>
    <em>
      When drawing, record <code>(target, polygon)</code> pairs in the order
      they were drawn. To detect a hit, search the list of
      <code>(target, polygon)</code> pairs in reverse order for the target which
      is responsible for the topmost polygon underneath the pointer.
    </em>
  </blockquote>
  <div>
    <canvas id="recursion"></canvas>
  </div>
  <div>
    <label>height </label>
    <input id="button-height" type="number" min="100" max="200" />
    <label>width </label>
    <input id="button-width" type="number" min="120" max="500" />
    <label>border radius </label>
    <input id="button-radius" type="number" min="0" max="100" />
  </div>
  <script type="module" src="./demo/composition.js"></script>

  <p>
    Look what we have achieved! These are basically the
    <code>&lt;div/&gt;</code>'s and <code>&lt;button/&gt;</code>'s that you were
    introduced to when you first learned about developing user interfaces, but
    this time all built from pixels. Remember, all we have used are
    <em
      >an array of pixels, a tree of polygons, a list of commands, some basic
      algebra and a bunch of nested loops</em
    >!
  </p>
  <p>
    There is one last thing: Patinting objects on top of each other seems
    straightfoward, but what if there is some transparency? This is where the
    alpha channel in RGBA comes in. One of the many ways to paint a color
    \((r_1,g_1,b_1,a_1)\) on top of another color \((r_2,g_2,b_2,a_2)\) is to
    use the "over" operator, which computes a weighted average of the RGB
    channels of the two colors based on how much each color contributes to the
    final alpha value: $$ a = a_1 + a_2 (1-a_1)$$ $$(r,g,b) =
    \frac{a_1}{a}(r_1,g_1,b_1) + \frac{a_2(1-a_1)}{a}(r_2,g_2,b_2)$$
  </p>
  <p>
    How about the frosted glass, i.e. Gaussian blur, effect? This is produced by
    a discrete convolution with a Gaussian filter. What the convolution does if
    replacing each pixel with
    <em>a weight average of a square neighborhood centered at the pixel</em>,
    where the weight diminishes with distance, according to the 2D Gaussian
    function: $$G(x,y) =
    \frac{1}{2\pi\sigma^2}\exp\left(-\frac{x^2+y^2}{2\sigma^2}\right)$$ The
    filter/convolution is defined as: $$Output(x,y) = \frac{1}{C}\sum_{u=-k}^{k}
    \sum_{v=-k}^{k} G(u,v)Input(x-u, y-v)$$ $$C = \sum_{u=-k}^{k}
    \sum_{v=-k}^{k}G(u,v)$$
  </p>
  <p>
    The canvas below demonstrates alpha compositing and Gaussian blur. You can
    drag the lens on the top left corner over the the text to see the blur
    effect.
  </p>
  <canvas id="glass"></canvas>
  <div>
    <label>alpha </label>
    <input id="alpha" type="number" min="0" max="1" value="0.2" step="0.1" />
    <label>sigma </label>
    <input id="sigma" type="number" min="1" max="10" value="3" step="1" />
  </div>
  <script type="module" src="./demo/glass.js"></script>
</body>
